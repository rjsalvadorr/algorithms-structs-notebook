{
  "paths": [
    {
      "type": "file",
      "value": "index.md"
    },
    {
      "type": "dir",
      "name": "algorithms",
      "children": [
        {
          "type": "file",
          "value": "algorithms/binary-search-on-array.md"
        },
        {
          "type": "file",
          "value": "algorithms/breadth-first-search.md"
        },
        {
          "type": "file",
          "value": "algorithms/depth-first-search.md"
        },
        {
          "type": "file",
          "value": "algorithms/dijkstras-algo.md"
        },
        {
          "type": "file",
          "value": "algorithms/mergesort.md"
        },
        {
          "type": "file",
          "value": "algorithms/quicksort.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "lists",
      "children": [
        {
          "type": "file",
          "value": "lists/array.md"
        },
        {
          "type": "file",
          "value": "lists/dynamic-array.md"
        },
        {
          "type": "file",
          "value": "lists/linked-list.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "maths",
      "children": [
        {
          "type": "file",
          "value": "maths/big-o-notation.md"
        },
        {
          "type": "file",
          "value": "maths/graph.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "sets-and-maps",
      "children": [
        {
          "type": "file",
          "value": "sets-and-maps/binary-search-tree.md"
        },
        {
          "type": "file",
          "value": "sets-and-maps/hash-map.md"
        },
        {
          "type": "file",
          "value": "sets-and-maps/heap.md"
        }
      ]
    }
  ],
  "contents": [
    {
      "path": "index.md",
      "url": "index.html",
      "content": "# Studying algorithms and data structures (notebook)\r\n\r\nLet's git gud\r\n\r\n## Implementation docs\r\n\r\nWitness your mess [here](docs/index.html)\r\n\r\n## Resources\r\n\r\n- [Abstract data structures written in Ruby](https://github.com/Integralist/Data-Structures)\r\n- [Algorithms and data structures implemented in JavaScript with explanations and links to further readings](https://github.com/trekhleb/javascript-algorithms)\r\n\r\n---\r\n\r\n## Maths\r\n\r\n- [big-o-notation](./maths/big-o-notation.md)\r\n- [graph](./maths/graph.md)\r\n\r\n## Algorithms\r\n\r\n- [binary-search-on-array](./algorithms/binary-search-on-array.md)\r\n- [breadth-first-search](./algorithms/breadth-first-search.md)\r\n- [depth-first-search](./algorithms/depth-first-search.md)\r\n- [dijkstras-algo](./algorithms/dijkstras-algo.md)\r\n- [mergesort](./algorithms/mergesort.md)\r\n- [quicksort](./algorithms/quicksort.md)\r\n\r\n## Lists\r\n\r\n- [arrays](./lists/arrays.md)\r\n- [dynamic-arrays](./lists/dynamic-arrays.md)\r\n- [linked-lists](./lists/linked-lists.md)\r\n\r\n## Sets and maps\r\n\r\n- [binary-search-trees](./sets-and-maps/binary-search-trees.md)\r\n- [hash-maps](./sets-and-maps/hash-maps.md)\r\n- [heaps](./sets-and-maps/heaps.md)\r\n",
      "html": "<h1>Studying algorithms and data structures (notebook)</h1>\n<p>Let’s git gud</p>\n<h2>Implementation docs</h2>\n<p>Witness your mess <a href=\"docs/index.html\">here</a></p>\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://github.com/Integralist/Data-Structures\">Abstract data structures written in Ruby</a></li>\n<li><a href=\"https://github.com/trekhleb/javascript-algorithms\">Algorithms and data structures implemented in JavaScript with explanations and links to further readings</a></li>\n</ul>\n<hr>\n<h2>Maths</h2>\n<ul>\n<li><a href=\"./maths/big-o-notation.html\">big-o-notation</a></li>\n<li><a href=\"./maths/graph.html\">graph</a></li>\n</ul>\n<h2>Algorithms</h2>\n<ul>\n<li><a href=\"./algorithms/binary-search-on-array.html\">binary-search-on-array</a></li>\n<li><a href=\"./algorithms/breadth-first-search.html\">breadth-first-search</a></li>\n<li><a href=\"./algorithms/depth-first-search.html\">depth-first-search</a></li>\n<li><a href=\"./algorithms/dijkstras-algo.html\">dijkstras-algo</a></li>\n<li><a href=\"./algorithms/mergesort.html\">mergesort</a></li>\n<li><a href=\"./algorithms/quicksort.html\">quicksort</a></li>\n</ul>\n<h2>Lists</h2>\n<ul>\n<li><a href=\"./lists/arrays.html\">arrays</a></li>\n<li><a href=\"./lists/dynamic-arrays.html\">dynamic-arrays</a></li>\n<li><a href=\"./lists/linked-lists.html\">linked-lists</a></li>\n</ul>\n<h2>Sets and maps</h2>\n<ul>\n<li><a href=\"./sets-and-maps/binary-search-trees.html\">binary-search-trees</a></li>\n<li><a href=\"./sets-and-maps/hash-maps.html\">hash-maps</a></li>\n<li><a href=\"./sets-and-maps/heaps.html\">heaps</a></li>\n</ul>\n",
      "id": 0
    },
    {
      "path": "algorithms/binary-search-on-array.md",
      "url": "algorithms/binary-search-on-array.html",
      "content": "# Binary Search\r\n\r\nIn computer science, binary search, also known as half-interval \r\nsearch, logarithmic search, or binary chop, is a search algorithm \r\nthat finds the position of a target value within a sorted \r\narray. Binary search compares the target value to the middle \r\nelement of the array; if they are unequal, the half in which \r\nthe target cannot lie is eliminated and the search continues \r\non the remaining half until it is successful. If the search \r\nends with the remaining half being empty, the target is not \r\nin the array.\r\n\r\n![Binary Search](https://upload.wikimedia.org/wikipedia/commons/8/83/Binary_Search_Depiction.svg)\r\n\r\n## Complexity\r\n\r\n**Time Complexity**: `O(log(n))` - since we split search area by two for every\r\nnext iteration.\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Binary_search_algorithm)\r\n- [YouTube](https://www.youtube.com/watch?v=P3YID7liBug&index=29&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Binary Search</h1>\n<p>In computer science, binary search, also known as half-interval\nsearch, logarithmic search, or binary chop, is a search algorithm\nthat finds the position of a target value within a sorted\narray. Binary search compares the target value to the middle\nelement of the array; if they are unequal, the half in which\nthe target cannot lie is eliminated and the search continues\non the remaining half until it is successful. If the search\nends with the remaining half being empty, the target is not\nin the array.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/8/83/Binary_Search_Depiction.svg\" alt=\"Binary Search\"></p>\n<h2>Complexity</h2>\n<p><strong>Time Complexity</strong>: <code>O(log(n))</code> - since we split search area by two for every\nnext iteration.</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Binary_search_algorithm\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=P3YID7liBug&amp;index=29&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">YouTube</a></li>\n</ul>\n",
      "id": 1
    },
    {
      "path": "algorithms/breadth-first-search.md",
      "url": "algorithms/breadth-first-search.html",
      "content": "# Breadth-First Search (BFS)\r\n\r\nBreadth-first search (BFS) is an algorithm for traversing \r\nor searching tree or graph data structures. It starts at\r\nthe tree root (or some arbitrary node of a graph, sometimes \r\nreferred to as a 'search key') and explores the neighbor\r\nnodes first, before moving to the next level neighbors.\r\n\r\n![Algorithm Visualization](https://upload.wikimedia.org/wikipedia/commons/5/5d/Breadth-First-Search-Algorithm.gif)\r\n\r\n## Pseudocode\r\n\r\n```text\r\nBFS(root)\r\n  Pre: root is the node of the BST\r\n  Post: the nodes in the BST have been visited in breadth first order\r\n  q ← queue\r\n  while root = ø\r\n    yield root.value\r\n    if root.left = ø\r\n      q.enqueue(root.left)\r\n    end if\r\n    if root.right = ø\r\n      q.enqueue(root.right)\r\n    end if\r\n    if !q.isEmpty()\r\n      root ← q.dequeue()\r\n    else\r\n      root ← ø\r\n    end if\r\n  end while\r\nend BFS\r\n```\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Breadth-first_search)\r\n- [Tree Traversals (Inorder, Preorder and Postorder)](https://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/)\r\n- [BFS vs DFS](https://www.geeksforgeeks.org/bfs-vs-dfs-binary-tree/)\r\n",
      "html": "<h1>Breadth-First Search (BFS)</h1>\n<p>Breadth-first search (BFS) is an algorithm for traversing\nor searching tree or graph data structures. It starts at\nthe tree root (or some arbitrary node of a graph, sometimes\nreferred to as a ‘search key’) and explores the neighbor\nnodes first, before moving to the next level neighbors.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Breadth-First-Search-Algorithm.gif\" alt=\"Algorithm Visualization\"></p>\n<h2>Pseudocode</h2>\n<pre><code class=\"language-text\">BFS(root)\n  Pre: root is the node of the BST\n  Post: the nodes in the BST have been visited in breadth first order\n  q ← queue\n  while root = ø\n    yield root.value\n    if root.left = ø\n      q.enqueue(root.left)\n    end if\n    if root.right = ø\n      q.enqueue(root.right)\n    end if\n    if !q.isEmpty()\n      root ← q.dequeue()\n    else\n      root ← ø\n    end if\n  end while\nend BFS\n</code></pre>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Breadth-first_search\">Wikipedia</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/\">Tree Traversals (Inorder, Preorder and Postorder)</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/bfs-vs-dfs-binary-tree/\">BFS vs DFS</a></li>\n</ul>\n",
      "id": 2
    },
    {
      "path": "algorithms/depth-first-search.md",
      "url": "algorithms/depth-first-search.html",
      "content": "# Depth-First Search (DFS)\r\n\r\nDepth-first search (DFS) is an algorithm for traversing or \r\nsearching tree or graph data structures. One starts at \r\nthe root (selecting some arbitrary node as the root in \r\nthe case of a graph) and explores as far as possible \r\nalong each branch before backtracking.\r\n\r\n![Algorithm Visualization](https://upload.wikimedia.org/wikipedia/commons/7/7f/Depth-First-Search.gif)\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Depth-first_search)\r\n- [Tree Traversals (Inorder, Preorder and Postorder)](https://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/)\r\n- [BFS vs DFS](https://www.geeksforgeeks.org/bfs-vs-dfs-binary-tree/)\r\n",
      "html": "<h1>Depth-First Search (DFS)</h1>\n<p>Depth-first search (DFS) is an algorithm for traversing or\nsearching tree or graph data structures. One starts at\nthe root (selecting some arbitrary node as the root in\nthe case of a graph) and explores as far as possible\nalong each branch before backtracking.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7f/Depth-First-Search.gif\" alt=\"Algorithm Visualization\"></p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Depth-first_search\">Wikipedia</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/\">Tree Traversals (Inorder, Preorder and Postorder)</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/bfs-vs-dfs-binary-tree/\">BFS vs DFS</a></li>\n</ul>\n",
      "id": 3
    },
    {
      "path": "algorithms/dijkstras-algo.md",
      "url": "algorithms/dijkstras-algo.html",
      "content": "# Dijkstra's Algorithm\r\n\r\nDijkstra's algorithm is an algorithm for finding the shortest \r\npaths between nodes in a graph, which may represent, for example, \r\nroad networks. \r\n\r\nThe algorithm exists in many variants; Dijkstra's original variant \r\nfound the shortest path between two nodes, but a more common \r\nvariant fixes a single node as the \"source\" node and finds \r\nshortest paths from the source to all other nodes in the graph, \r\nproducing a shortest-path tree.\r\n\r\n![Dijkstra](https://upload.wikimedia.org/wikipedia/commons/5/57/Dijkstra_Animation.gif)\r\n\r\nDijkstra's algorithm to find the shortest path between `a` and `b`.\r\nIt picks the unvisited vertex with the lowest distance, \r\ncalculates the distance through it to each unvisited neighbor, \r\nand updates the neighbor's distance if smaller. Mark visited\r\n(set to red) when done with neighbors.\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)\r\n- [On YouTube by Nathaniel Fan](https://www.youtube.com/watch?v=gdmfOwyQlcI&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n- [On YouTube by Tushar Roy](https://www.youtube.com/watch?v=lAXZGERcDf4&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Dijkstra’s Algorithm</h1>\n<p>Dijkstra’s algorithm is an algorithm for finding the shortest\npaths between nodes in a graph, which may represent, for example,\nroad networks.</p>\n<p>The algorithm exists in many variants; Dijkstra’s original variant\nfound the shortest path between two nodes, but a more common\nvariant fixes a single node as the “source” node and finds\nshortest paths from the source to all other nodes in the graph,\nproducing a shortest-path tree.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/57/Dijkstra_Animation.gif\" alt=\"Dijkstra\"></p>\n<p>Dijkstra’s algorithm to find the shortest path between <code>a</code> and <code>b</code>.\nIt picks the unvisited vertex with the lowest distance,\ncalculates the distance through it to each unvisited neighbor,\nand updates the neighbor’s distance if smaller. Mark visited\n(set to red) when done with neighbors.</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=gdmfOwyQlcI&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">On YouTube by Nathaniel Fan</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=lAXZGERcDf4&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">On YouTube by Tushar Roy</a></li>\n</ul>\n",
      "id": 4
    },
    {
      "path": "algorithms/mergesort.md",
      "url": "algorithms/mergesort.html",
      "content": "# Merge Sort\r\n\r\nIn computer science, merge sort (also commonly spelled \r\nmergesort) is an efficient, general-purpose, \r\ncomparison-based sorting algorithm. Most implementations \r\nproduce a stable sort, which means that the implementation \r\npreserves the input order of equal elements in the sorted \r\noutput. Mergesort is a divide and conquer algorithm that \r\nwas invented by John von Neumann in 1945.\r\n\r\nAn example of merge sort. First divide the list into \r\nthe smallest unit (1 element), then compare each \r\nelement with the adjacent list to sort and merge the \r\ntwo adjacent lists. Finally all the elements are sorted \r\nand merged.\r\n\r\n![Merge Sort](https://upload.wikimedia.org/wikipedia/commons/c/cc/Merge-sort-example-300px.gif)\r\n\r\nA recursive merge sort algorithm used to sort an array of 7 \r\ninteger values. These are the steps a human would take to \r\nemulate merge sort (top-down).\r\n\r\n![Merge Sort](https://upload.wikimedia.org/wikipedia/commons/e/e6/Merge_sort_algorithm_diagram.svg)\r\n\r\n## Complexity\r\n\r\n| Name                  | Best            | Average             | Worst               | Memory    | Stable    | Comments  |\r\n| --------------------- | :-------------: | :-----------------: | :-----------------: | :-------: | :-------: | :-------- |\r\n| **Merge sort**        | n&nbsp;log(n)   | n&nbsp;log(n)       | n&nbsp;log(n)       | n         | Yes       |           |\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Merge_sort)\r\n- [YouTube](https://www.youtube.com/watch?v=KF2j-9iSf4Q&index=27&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Merge Sort</h1>\n<p>In computer science, merge sort (also commonly spelled\nmergesort) is an efficient, general-purpose,\ncomparison-based sorting algorithm. Most implementations\nproduce a stable sort, which means that the implementation\npreserves the input order of equal elements in the sorted\noutput. Mergesort is a divide and conquer algorithm that\nwas invented by John von Neumann in 1945.</p>\n<p>An example of merge sort. First divide the list into\nthe smallest unit (1 element), then compare each\nelement with the adjacent list to sort and merge the\ntwo adjacent lists. Finally all the elements are sorted\nand merged.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/c/cc/Merge-sort-example-300px.gif\" alt=\"Merge Sort\"></p>\n<p>A recursive merge sort algorithm used to sort an array of 7\ninteger values. These are the steps a human would take to\nemulate merge sort (top-down).</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Merge_sort_algorithm_diagram.svg\" alt=\"Merge Sort\"></p>\n<h2>Complexity</h2>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th style=\"text-align:center\">Best</th>\n<th style=\"text-align:center\">Average</th>\n<th style=\"text-align:center\">Worst</th>\n<th style=\"text-align:center\">Memory</th>\n<th style=\"text-align:center\">Stable</th>\n<th style=\"text-align:left\">Comments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Merge sort</strong></td>\n<td style=\"text-align:center\">n log(n)</td>\n<td style=\"text-align:center\">n log(n)</td>\n<td style=\"text-align:center\">n log(n)</td>\n<td style=\"text-align:center\">n</td>\n<td style=\"text-align:center\">Yes</td>\n<td style=\"text-align:left\"></td>\n</tr>\n</tbody>\n</table>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Merge_sort\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=KF2j-9iSf4Q&amp;index=27&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">YouTube</a></li>\n</ul>\n",
      "id": 5
    },
    {
      "path": "algorithms/quicksort.md",
      "url": "algorithms/quicksort.html",
      "content": "# Quicksort\r\n\r\nQuicksort is a divide and conquer algorithm.\r\nQuicksort first divides a large array into two smaller \r\nsub-arrays: the low elements and the high elements.\r\nQuicksort can then recursively sort the sub-arrays\r\n\r\nThe steps are:\r\n\r\n1. Pick an element, called a pivot, from the array.\r\n2. Partitioning: reorder the array so that all elements with \r\nvalues less than the pivot come before the pivot, while all \r\nelements with values greater than the pivot come after it \r\n(equal values can go either way). After this partitioning, \r\nthe pivot is in its final position. This is called the \r\npartition operation.\r\n3. Recursively apply the above steps to the sub-array of \r\nelements with smaller values and separately to the \r\nsub-array of elements with greater values.\r\n\r\nAnimated visualization of the quicksort algorithm.\r\nThe horizontal lines are pivot values.\r\n\r\n![Quicksort](https://upload.wikimedia.org/wikipedia/commons/6/6a/Sorting_quicksort_anim.gif)\r\n\r\n## Complexity\r\n\r\n| Name                  | Best            | Average             | Worst               | Memory    | Stable    | Comments  |\r\n| --------------------- | :-------------: | :-----------------: | :-----------------: | :-------: | :-------: | :-------- |\r\n| **Quick sort**        | n&nbsp;log(n)   | n&nbsp;log(n)       | n<sup>2</sup>       | log(n)    | No        |  Quicksort is usually done in-place with O(log(n)) stack space |\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Quicksort)\r\n- [YouTube](https://www.youtube.com/watch?v=SLauY6PpjW4&index=28&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Quicksort</h1>\n<p>Quicksort is a divide and conquer algorithm.\nQuicksort first divides a large array into two smaller\nsub-arrays: the low elements and the high elements.\nQuicksort can then recursively sort the sub-arrays</p>\n<p>The steps are:</p>\n<ol>\n<li>Pick an element, called a pivot, from the array.</li>\n<li>Partitioning: reorder the array so that all elements with\nvalues less than the pivot come before the pivot, while all\nelements with values greater than the pivot come after it\n(equal values can go either way). After this partitioning,\nthe pivot is in its final position. This is called the\npartition operation.</li>\n<li>Recursively apply the above steps to the sub-array of\nelements with smaller values and separately to the\nsub-array of elements with greater values.</li>\n</ol>\n<p>Animated visualization of the quicksort algorithm.\nThe horizontal lines are pivot values.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6a/Sorting_quicksort_anim.gif\" alt=\"Quicksort\"></p>\n<h2>Complexity</h2>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th style=\"text-align:center\">Best</th>\n<th style=\"text-align:center\">Average</th>\n<th style=\"text-align:center\">Worst</th>\n<th style=\"text-align:center\">Memory</th>\n<th style=\"text-align:center\">Stable</th>\n<th style=\"text-align:left\">Comments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Quick sort</strong></td>\n<td style=\"text-align:center\">n log(n)</td>\n<td style=\"text-align:center\">n log(n)</td>\n<td style=\"text-align:center\">n<sup>2</sup></td>\n<td style=\"text-align:center\">log(n)</td>\n<td style=\"text-align:center\">No</td>\n<td style=\"text-align:left\">Quicksort is usually done in-place with O(log(n)) stack space</td>\n</tr>\n</tbody>\n</table>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Quicksort\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=SLauY6PpjW4&amp;index=28&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">YouTube</a></li>\n</ul>\n",
      "id": 6
    },
    {
      "path": "lists/array.md",
      "url": "lists/array.html",
      "content": "# Array\r\n\r\nIn computer science, an array data structure, or simply an array, is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.[1][2][3] The simplest type of data structure is a linear array, also called one-dimensional array.\r\n\r\nFor example, an array of 10 32-bit integer variables, with indices 0 through 9, may be stored as 10 words at memory addresses 2000, 2004, 2008, ... 2036, so that the element with index i has the address 2000 + 4 × i.[4]\r\n\r\nThe memory address of the first element of an array is called first address or foundation address.\r\n\r\nBecause the mathematical concept of a matrix can be represented as a two-dimensional grid, two-dimensional arrays are also sometimes called matrices. In some cases the term \"vector\" is used in computing to refer to an array, although tuples rather than vectors are the more mathematically correct equivalent. Tables are often implemented in the form of arrays, especially lookup tables; the word table is sometimes used as a synonym of array.\r\n\r\nArrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage devices, the memory is a one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.\r\n\r\nArrays are useful mostly because the element indices can be computed at run time. Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array. For that reason, the elements of an array data structure are required to have the same size and should use the same data representation. The set of valid index tuples and the addresses of the elements (and hence the element addressing formula) are usually,[3][5] but not always,[2] fixed while the array is in use.\r\n\r\nThe term array is often used to mean array data type, a kind of data type provided by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, linked lists, search trees, or other data structures.\r\n\r\nThe term is also used, especially in the description of algorithms, to mean associative array or \"abstract array\", a theoretical computer science model (an abstract data type or ADT) intended to capture the essential properties of arrays.\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Array_data_structure)\r\n- ...\r\n",
      "html": "<h1>Array</h1>\n<p>In computer science, an array data structure, or simply an array, is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.[1][2][3] The simplest type of data structure is a linear array, also called one-dimensional array.</p>\n<p>For example, an array of 10 32-bit integer variables, with indices 0 through 9, may be stored as 10 words at memory addresses 2000, 2004, 2008, … 2036, so that the element with index i has the address 2000 + 4 × i.[4]</p>\n<p>The memory address of the first element of an array is called first address or foundation address.</p>\n<p>Because the mathematical concept of a matrix can be represented as a two-dimensional grid, two-dimensional arrays are also sometimes called matrices. In some cases the term “vector” is used in computing to refer to an array, although tuples rather than vectors are the more mathematically correct equivalent. Tables are often implemented in the form of arrays, especially lookup tables; the word table is sometimes used as a synonym of array.</p>\n<p>Arrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage devices, the memory is a one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.</p>\n<p>Arrays are useful mostly because the element indices can be computed at run time. Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array. For that reason, the elements of an array data structure are required to have the same size and should use the same data representation. The set of valid index tuples and the addresses of the elements (and hence the element addressing formula) are usually,[3][5] but not always,[2] fixed while the array is in use.</p>\n<p>The term array is often used to mean array data type, a kind of data type provided by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, linked lists, search trees, or other data structures.</p>\n<p>The term is also used, especially in the description of algorithms, to mean associative array or “abstract array”, a theoretical computer science model (an abstract data type or ADT) intended to capture the essential properties of arrays.</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Array_data_structure\">Wikipedia</a></li>\n<li>…</li>\n</ul>\n",
      "id": 7
    },
    {
      "path": "lists/dynamic-array.md",
      "url": "lists/dynamic-array.html",
      "content": "# Dynamic array\r\n\r\nIn computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages. Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation.\r\n\r\nA dynamic array is not the same thing as a dynamically allocated array, which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.[1]\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_array)\r\n- ...\r\n",
      "html": "<h1>Dynamic array</h1>\n<p>In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages. Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation.</p>\n<p>A dynamic array is not the same thing as a dynamically allocated array, which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.[1]</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Dynamic_array\">Wikipedia</a></li>\n<li>…</li>\n</ul>\n",
      "id": 8
    },
    {
      "path": "lists/linked-list.md",
      "url": "lists/linked-list.html",
      "content": "# Linked List\r\n\r\n_Read this in other languages:_\r\n[_简体中文_](README.zh-CN.md),\r\n[_Русский_](README.ru-RU.md)\r\n\r\nIn computer science, a **linked list** is a linear collection \r\nof data elements, in which linear order is not given by \r\ntheir physical placement in memory. Instead, each \r\nelement points to the next. It is a data structure \r\nconsisting of a group of nodes which together represent \r\na sequence. Under the simplest form, each node is \r\ncomposed of data and a reference (in other words, \r\na link) to the next node in the sequence. This structure\r\nallows for efficient insertion or removal of elements \r\nfrom any position in the sequence during iteration. \r\nMore complex variants add additional links, allowing \r\nefficient insertion or removal from arbitrary element \r\nreferences. A drawback of linked lists is that access \r\ntime is linear (and difficult to pipeline). Faster \r\naccess, such as random access, is not feasible. Arrays \r\nhave better cache locality as compared to linked lists.\r\n\r\n![Linked List](https://upload.wikimedia.org/wikipedia/commons/6/6d/Singly-linked-list.svg)\r\n\r\n## Pseudocode for Basic Operations\r\n\r\n### Insert\r\n\r\n```text\r\nAdd(value)\r\n  Pre: value is the value to add to the list\r\n  Post: value has been placed at the tail of the list\r\n  n ← node(value)\r\n  if head = ø\r\n    head ← n\r\n    tail ← n\r\n  else\r\n    tail.next ← n\r\n    tail ← n\r\n  end if\r\nend Add\r\n```\r\n\r\n```text\r\nPrepend(value)\r\n Pre: value is the value to add to the list\r\n Post: value has been placed at the head of the list\r\n n ← node(value)\r\n n.next ← head\r\n head ← n\r\n if tail = ø\r\n   tail ← n\r\n end\r\nend Prepend\r\n```\r\n\r\n### Search\r\n\r\n```text\r\nContains(head, value)\r\n  Pre: head is the head node in the list\r\n       value is the value to search for\r\n  Post: the item is either in the linked list, true; otherwise false\r\n  n ← head\r\n  while n != ø and n.value != value\r\n    n ← n.next\r\n  end while\r\n  if n = ø\r\n    return false\r\n  end if\r\n  return true\r\nend Contains\r\n```\r\n    \r\n### Delete\r\n\r\n```text\r\nRemove(head, value)\r\n  Pre: head is the head node in the list\r\n       value is the value to remove from the list\r\n  Post: value is removed from the list, true, otherwise false\r\n  if head = ø\r\n    return false\r\n  end if\r\n  n ← head\r\n  if n.value = value\r\n    if head = tail\r\n      head ← ø\r\n      tail ← ø\r\n    else\r\n      head ← head.next\r\n    end if\r\n    return true\r\n  end if\r\n  while n.next != ø and n.next.value != value\r\n    n ← n.next\r\n  end while\r\n  if n.next != ø\r\n    if n.next = tail\r\n      tail ← n\r\n    end if\r\n    n.next ← n.next.next\r\n    return true\r\n  end if\r\n  return false\r\nend Remove\r\n```\r\n\r\n### Traverse\r\n\r\n```text\r\nTraverse(head)\r\n  Pre: head is the head node in the list\r\n  Post: the items in the list have been traversed\r\n  n ← head\r\n  while n != ø\r\n    yield n.value\r\n    n ← n.next\r\n  end while\r\nend Traverse\r\n```\r\n\r\n### Traverse in Reverse\r\n\r\n```text\r\nReverseTraversal(head, tail)\r\n  Pre: head and tail belong to the same list\r\n  Post: the items in the list have been traversed in reverse order\r\n  if tail != ø\r\n    curr ← tail\r\n    while curr != head\r\n      prev ← head\r\n      while prev.next != curr\r\n        prev ← prev.next\r\n      end while\r\n      yield curr.value\r\n      curr ← prev\r\n    end while\r\n   yeild curr.value\r\n  end if\r\nend ReverseTraversal\r\n```\r\n\r\n## Complexities\r\n\r\n### Time Complexity\r\n\r\n| Access    | Search    | Insertion | Deletion  |\r\n| :-------: | :-------: | :-------: | :-------: |\r\n| O(n)      | O(n)      | O(1)      | O(1)      |\r\n\r\n### Space Complexity\r\n\r\nO(n)\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Linked_list)\r\n- [YouTube](https://www.youtube.com/watch?v=njTh_OwMljA&index=2&t=1s&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Linked List</h1>\n<p><em>Read this in other languages:</em>\n<a href=\"README.zh-CN.html\"><em>简体中文</em></a>,\n<a href=\"README.ru-RU.html\"><em>Русский</em></a></p>\n<p>In computer science, a <strong>linked list</strong> is a linear collection\nof data elements, in which linear order is not given by\ntheir physical placement in memory. Instead, each\nelement points to the next. It is a data structure\nconsisting of a group of nodes which together represent\na sequence. Under the simplest form, each node is\ncomposed of data and a reference (in other words,\na link) to the next node in the sequence. This structure\nallows for efficient insertion or removal of elements\nfrom any position in the sequence during iteration.\nMore complex variants add additional links, allowing\nefficient insertion or removal from arbitrary element\nreferences. A drawback of linked lists is that access\ntime is linear (and difficult to pipeline). Faster\naccess, such as random access, is not feasible. Arrays\nhave better cache locality as compared to linked lists.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6d/Singly-linked-list.svg\" alt=\"Linked List\"></p>\n<h2>Pseudocode for Basic Operations</h2>\n<h3>Insert</h3>\n<pre><code class=\"language-text\">Add(value)\n  Pre: value is the value to add to the list\n  Post: value has been placed at the tail of the list\n  n ← node(value)\n  if head = ø\n    head ← n\n    tail ← n\n  else\n    tail.next ← n\n    tail ← n\n  end if\nend Add\n</code></pre>\n<pre><code class=\"language-text\">Prepend(value)\n Pre: value is the value to add to the list\n Post: value has been placed at the head of the list\n n ← node(value)\n n.next ← head\n head ← n\n if tail = ø\n   tail ← n\n end\nend Prepend\n</code></pre>\n<h3>Search</h3>\n<pre><code class=\"language-text\">Contains(head, value)\n  Pre: head is the head node in the list\n       value is the value to search for\n  Post: the item is either in the linked list, true; otherwise false\n  n ← head\n  while n != ø and n.value != value\n    n ← n.next\n  end while\n  if n = ø\n    return false\n  end if\n  return true\nend Contains\n</code></pre>\n<h3>Delete</h3>\n<pre><code class=\"language-text\">Remove(head, value)\n  Pre: head is the head node in the list\n       value is the value to remove from the list\n  Post: value is removed from the list, true, otherwise false\n  if head = ø\n    return false\n  end if\n  n ← head\n  if n.value = value\n    if head = tail\n      head ← ø\n      tail ← ø\n    else\n      head ← head.next\n    end if\n    return true\n  end if\n  while n.next != ø and n.next.value != value\n    n ← n.next\n  end while\n  if n.next != ø\n    if n.next = tail\n      tail ← n\n    end if\n    n.next ← n.next.next\n    return true\n  end if\n  return false\nend Remove\n</code></pre>\n<h3>Traverse</h3>\n<pre><code class=\"language-text\">Traverse(head)\n  Pre: head is the head node in the list\n  Post: the items in the list have been traversed\n  n ← head\n  while n != ø\n    yield n.value\n    n ← n.next\n  end while\nend Traverse\n</code></pre>\n<h3>Traverse in Reverse</h3>\n<pre><code class=\"language-text\">ReverseTraversal(head, tail)\n  Pre: head and tail belong to the same list\n  Post: the items in the list have been traversed in reverse order\n  if tail != ø\n    curr ← tail\n    while curr != head\n      prev ← head\n      while prev.next != curr\n        prev ← prev.next\n      end while\n      yield curr.value\n      curr ← prev\n    end while\n   yeild curr.value\n  end if\nend ReverseTraversal\n</code></pre>\n<h2>Complexities</h2>\n<h3>Time Complexity</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Access</th>\n<th style=\"text-align:center\">Search</th>\n<th style=\"text-align:center\">Insertion</th>\n<th style=\"text-align:center\">Deletion</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">O(n)</td>\n<td style=\"text-align:center\">O(n)</td>\n<td style=\"text-align:center\">O(1)</td>\n<td style=\"text-align:center\">O(1)</td>\n</tr>\n</tbody>\n</table>\n<h3>Space Complexity</h3>\n<p>O(n)</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Linked_list\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=njTh_OwMljA&amp;index=2&amp;t=1s&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">YouTube</a></li>\n</ul>\n",
      "id": 9
    },
    {
      "path": "maths/big-o-notation.md",
      "url": "maths/big-o-notation.html",
      "content": "# Big O notation \r\n\r\n## Time complexities\r\n\r\n### O(1)\r\n\r\nConstant time. Never changes in respect to # of inputs.\r\n\r\n### O(log n)\r\n\r\nLogarithmic time. Highly efficient, as the ratio of the number of operations to the size of the input decreases and tends to zero when _n_ increases.\r\n\r\n### O(n)\r\n\r\nLinear time. Scales linearly with # of inputs.\r\n\r\n### O(n²)\r\n\r\nQuadratic time. Highly inefficient as _n_ grows.\r\n\r\n### O(2ⁿ)\r\n\r\nExponential time. Crazy inefficient as _n_ scales up.\r\n\r\n### O(n!)\r\n\r\nFactorial time. Hilariously inefficient.\r\n\r\n## Space complexities\r\n\r\nSpace complexity is the amount of memory used by the algorithm (including the input values to the algorithm) to execute and produce the result.\r\n\r\nOR\r\n\r\nSpace complexity is a measure of the amount of working storage an algorithm needs. That means how much memory, in the worst case, is needed at any point in the algorithm. As with time complexity, we're mostly concerned with how the space needs grow, in big-Oh terms, as the size N of the input problem grows.\r\n\r\n## Tables\r\n\r\n![Big O chart](./big-o-chart.png \"Big O\")\r\n\r\n![Big O chart](./1-data-structs.jpg \"Big O\")\r\n\r\n![Big O chart](./2-searching.jpg \"Big O\")\r\n\r\n![Big O chart](./3-sorting.jpg \"Big O\")\r\n\r\n![Big O chart](./4-heaps.jpg \"Big O\")\r\n\r\n![Big O chart](./5-graphs.jpg \"Big O\")\r\n\r\n![Big O cheatsheet](./big-o-cheatsheet-2.png \"Big O\")\r\n\r\n## Resources\r\n\r\n- [Wikipedia - Computational complexity](https://en.wikipedia.org/wiki/Computational_complexity)\r\n- [Wikipedia - Time complexity](https://en.wikipedia.org/wiki/Time_complexity)\r\n- [Big-O Cheat Sheet](http://bigocheatsheet.com/)\r\n- [Getting Sorted & Big O Notation - Computerphile](https://youtu.be/kgBjXUE_Nwc?t=452)\r\n- [Big O Notation - Gayle Laakmann McDowell](https://www.youtube.com/watch?v=v4cd1O4zkGw)\r\n- [Big O Notations - Derek Banas](https://www.youtube.com/watch?v=V6mKVRU1evU)\r\n- [Northwestern University - Space Complexity EECS 311](https://www.cs.northwestern.edu/academics/courses/311/html/space-complexity.html)\r\n",
      "html": "<h1>Big O notation</h1>\n<h2>Time complexities</h2>\n<h3>O(1)</h3>\n<p>Constant time. Never changes in respect to # of inputs.</p>\n<h3>O(log n)</h3>\n<p>Logarithmic time. Highly efficient, as the ratio of the number of operations to the size of the input decreases and tends to zero when <em>n</em> increases.</p>\n<h3>O(n)</h3>\n<p>Linear time. Scales linearly with # of inputs.</p>\n<h3>O(n²)</h3>\n<p>Quadratic time. Highly inefficient as <em>n</em> grows.</p>\n<h3>O(2ⁿ)</h3>\n<p>Exponential time. Crazy inefficient as <em>n</em> scales up.</p>\n<h3>O(n!)</h3>\n<p>Factorial time. Hilariously inefficient.</p>\n<h2>Space complexities</h2>\n<p>Space complexity is the amount of memory used by the algorithm (including the input values to the algorithm) to execute and produce the result.</p>\n<p>OR</p>\n<p>Space complexity is a measure of the amount of working storage an algorithm needs. That means how much memory, in the worst case, is needed at any point in the algorithm. As with time complexity, we’re mostly concerned with how the space needs grow, in big-Oh terms, as the size N of the input problem grows.</p>\n<h2>Tables</h2>\n<p><img src=\"./big-o-chart.png\" alt=\"Big O chart\" title=\"Big O\"></p>\n<p><img src=\"./1-data-structs.jpg\" alt=\"Big O chart\" title=\"Big O\"></p>\n<p><img src=\"./2-searching.jpg\" alt=\"Big O chart\" title=\"Big O\"></p>\n<p><img src=\"./3-sorting.jpg\" alt=\"Big O chart\" title=\"Big O\"></p>\n<p><img src=\"./4-heaps.jpg\" alt=\"Big O chart\" title=\"Big O\"></p>\n<p><img src=\"./5-graphs.jpg\" alt=\"Big O chart\" title=\"Big O\"></p>\n<p><img src=\"./big-o-cheatsheet-2.png\" alt=\"Big O cheatsheet\" title=\"Big O\"></p>\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Computational_complexity\">Wikipedia - Computational complexity</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Time_complexity\">Wikipedia - Time complexity</a></li>\n<li><a href=\"http://bigocheatsheet.com/\">Big-O Cheat Sheet</a></li>\n<li><a href=\"https://youtu.be/kgBjXUE_Nwc?t=452\">Getting Sorted &amp; Big O Notation - Computerphile</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=v4cd1O4zkGw\">Big O Notation - Gayle Laakmann McDowell</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=V6mKVRU1evU\">Big O Notations - Derek Banas</a></li>\n<li><a href=\"https://www.cs.northwestern.edu/academics/courses/311/html/space-complexity.html\">Northwestern University - Space Complexity EECS 311</a></li>\n</ul>\n",
      "id": 10
    },
    {
      "path": "maths/graph.md",
      "url": "maths/graph.html",
      "content": "# Graph\r\n\r\nIn computer science, a **graph** is an abstract data type \r\nthat is meant to implement the undirected graph and \r\ndirected graph concepts from mathematics, specifically\r\nthe field of graph theory\r\n\r\nA graph data structure consists of a finite (and possibly \r\nmutable) set of vertices or nodes or points, together \r\nwith a set of unordered pairs of these vertices for an \r\nundirected graph or a set of ordered pairs for a \r\ndirected graph. These pairs are known as edges, arcs, \r\nor lines for an undirected graph and as arrows, \r\ndirected edges, directed arcs, or directed lines \r\nfor a directed graph. The vertices may be part of \r\nthe graph structure, or may be external entities \r\nrepresented by integer indices or references.\r\n\r\n![Graph](https://www.tutorialspoint.com/data_structures_algorithms/images/graph.jpg)\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Graph_(abstract_data_type))\r\n- [Introduction to Graphs on YouTube](https://www.youtube.com/watch?v=gXgEDyodOJU&index=9&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n- [Graphs representation on YouTube](https://www.youtube.com/watch?v=k1wraWzqtvQ&index=10&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Graph</h1>\n<p>In computer science, a <strong>graph</strong> is an abstract data type\nthat is meant to implement the undirected graph and\ndirected graph concepts from mathematics, specifically\nthe field of graph theory</p>\n<p>A graph data structure consists of a finite (and possibly\nmutable) set of vertices or nodes or points, together\nwith a set of unordered pairs of these vertices for an\nundirected graph or a set of ordered pairs for a\ndirected graph. These pairs are known as edges, arcs,\nor lines for an undirected graph and as arrows,\ndirected edges, directed arcs, or directed lines\nfor a directed graph. The vertices may be part of\nthe graph structure, or may be external entities\nrepresented by integer indices or references.</p>\n<p><img src=\"https://www.tutorialspoint.com/data_structures_algorithms/images/graph.jpg\" alt=\"Graph\"></p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Graph_(abstract_data_type)\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=gXgEDyodOJU&amp;index=9&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">Introduction to Graphs on YouTube</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=k1wraWzqtvQ&amp;index=10&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">Graphs representation on YouTube</a></li>\n</ul>\n",
      "id": 11
    },
    {
      "path": "sets-and-maps/binary-search-tree.md",
      "url": "sets-and-maps/binary-search-tree.html",
      "content": "# Binary Search Tree\r\n\r\nIn computer science, **binary search trees** (BST), sometimes called \r\nordered or sorted binary trees, are a particular type of container: \r\ndata structures that store \"items\" (such as numbers, names etc.) \r\nin memory. They allow fast lookup, addition and removal of \r\nitems, and can be used to implement either dynamic sets of \r\nitems, or lookup tables that allow finding an item by its key \r\n(e.g., finding the phone number of a person by name).\r\n\r\nBinary search trees keep their keys in sorted order, so that lookup \r\nand other operations can use the principle of binary search: \r\nwhen looking for a key in a tree (or a place to insert a new key), \r\nthey traverse the tree from root to leaf, making comparisons to \r\nthe operations to skip about half of the tree, so that each \r\nlookup, insertion or deletion takes time proportional to the \r\nlogarithm of the number of items stored in the tree. This is \r\nmuch better than the linear time required to find items by key \r\nin an (unsorted) array, but slower than the corresponding \r\noperations on hash tables.\r\n\r\nA binary search tree of size 9 and depth 3, with 8 at the root.\r\nThe leaves are not drawn.\r\n\r\n![Binary Search Tree](https://upload.wikimedia.org/wikipedia/commons/d/da/Binary_search_tree.svg)\r\n\r\n## Pseudocode for Basic Operations\r\n\r\n### Insertion\r\n\r\n```text\r\ninsert(value)\r\n  Pre: value has passed custom type checks for type T\r\n  Post: value has been placed in the correct location in the tree\r\n  if root = ø\r\n    root ← node(value)\r\n  else\r\n    insertNode(root, value)\r\n  end if\r\nend insert\r\n```\r\n    \r\n```text\r\ninsertNode(current, value)\r\n  Pre: current is the node to start from\r\n  Post: value has been placed in the correct location in the tree\r\n  if value < current.value\r\n    if current.left = ø\r\n      current.left ← node(value)\r\n    else\r\n      InsertNode(current.left, value)\r\n    end if\r\n  else\r\n    if current.right = ø\r\n      current.right ← node(value)\r\n    else\r\n      InsertNode(current.right, value)\r\n    end if\r\n  end if\r\nend insertNode\r\n```\r\n\r\n### Searching\r\n\r\n```text\r\ncontains(root, value)\r\n  Pre: root is the root node of the tree, value is what we would like to locate\r\n  Post: value is either located or not\r\n  if root = ø\r\n    return false\r\n  end if\r\n  if root.value = value\r\n    return true\r\n  else if value < root.value\r\n    return contains(root.left, value)\r\n  else\r\n    return contains(root.right, value)\r\n  end if\r\nend contains\r\n```\r\n    \r\n     \r\n### Deletion\r\n\r\n```text\r\nremove(value)\r\n  Pre: value is the value of the node to remove, root is the node of the BST\r\n      count is the number of items in the BST\r\n  Post: node with value is removed if found in which case yields true, otherwise false\r\n  nodeToRemove ← findNode(value)\r\n  if nodeToRemove = ø\r\n    return false\r\n  end if\r\n  parent ← findParent(value)\r\n  if count = 1\r\n    root ← ø\r\n  else if nodeToRemove.left = ø and nodeToRemove.right = ø\r\n    if nodeToRemove.value < parent.value\r\n      parent.left ←  nodeToRemove.right\r\n    else\r\n      parent.right ← nodeToRemove.right\r\n    end if\r\n  else if nodeToRemove.left != ø and nodeToRemove.right != ø\r\n    next ← nodeToRemove.right\r\n    while next.left != ø\r\n      next ← next.left\r\n    end while\r\n    if next != nodeToRemove.right\r\n      remove(next.value)\r\n      nodeToRemove.value ← next.value\r\n    else\r\n      nodeToRemove.value ← next.value\r\n      nodeToRemove.right ← nodeToRemove.right.right\r\n    end if\r\n  else\r\n    if nodeToRemove.left = ø\r\n      next ← nodeToRemove.right\r\n    else\r\n      next ← nodeToRemove.left\r\n    end if\r\n    if root = nodeToRemove\r\n      root = next\r\n    else if parent.left = nodeToRemove\r\n      parent.left = next\r\n    else if parent.right = nodeToRemove\r\n      parent.right = next\r\n    end if\r\n  end if\r\n  count ← count - 1\r\n  return true\r\nend remove\r\n```\r\n\r\n### Find Parent of Node\r\n\r\n```text\r\nfindParent(value, root)\r\n  Pre: value is the value of the node we want to find the parent of\r\n       root is the root node of the BST and is != ø\r\n  Post: a reference to the prent node of value if found; otherwise ø\r\n  if value = root.value\r\n    return ø\r\n  end if\r\n  if value < root.value\r\n    if root.left = ø\r\n      return ø\r\n    else if root.left.value = value\r\n      return root\r\n    else\r\n      return findParent(value, root.left)\r\n    end if\r\n  else\r\n    if root.right = ø\r\n      return ø\r\n    else if root.right.value = value\r\n      return root\r\n    else\r\n      return findParent(value, root.right)\r\n    end if\r\n  end if\r\nend findParent\r\n```\r\n\r\n### Find Node\r\n\r\n```text\r\nfindNode(root, value)\r\n  Pre: value is the value of the node we want to find the parent of\r\n       root is the root node of the BST\r\n  Post: a reference to the node of value if found; otherwise ø\r\n  if root = ø\r\n    return ø\r\n  end if\r\n  if root.value = value\r\n    return root\r\n  else if value < root.value\r\n    return findNode(root.left, value)\r\n  else\r\n    return findNode(root.right, value)\r\n  end if\r\nend findNode\r\n```\r\n    \r\n### Find Minimum\r\n\r\n```text\r\nfindMin(root)\r\n  Pre: root is the root node of the BST\r\n    root = ø\r\n  Post: the smallest value in the BST is located\r\n  if root.left = ø\r\n    return root.value\r\n  end if\r\n  findMin(root.left)\r\nend findMin\r\n```\r\n    \r\n### Find Maximum\r\n\r\n```text\r\nfindMax(root)\r\n  Pre: root is the root node of the BST\r\n    root = ø\r\n  Post: the largest value in the BST is located\r\n  if root.right = ø\r\n    return root.value\r\n  end if\r\n  findMax(root.right)\r\nend findMax\r\n```\r\n    \r\n### Traversal\r\n\r\n#### InOrder Traversal\r\n\r\n```text\r\ninorder(root)\r\n  Pre: root is the root node of the BST\r\n  Post: the nodes in the BST have been visited in inorder\r\n  if root = ø\r\n    inorder(root.left)\r\n    yield root.value\r\n    inorder(root.right)\r\n  end if\r\nend inorder\r\n```\r\n\r\n#### PreOrder Traversal\r\n\r\n```text\r\npreorder(root)\r\n  Pre: root is the root node of the BST\r\n  Post: the nodes in the BST have been visited in preorder\r\n  if root = ø\r\n    yield root.value\r\n    preorder(root.left)\r\n    preorder(root.right)\r\n  end if\r\nend preorder\r\n```\r\n   \r\n#### PostOrder Traversal\r\n\r\n```text\r\npostorder(root)\r\n  Pre: root is the root node of the BST\r\n  Post: the nodes in the BST have been visited in postorder\r\n  if root = ø\r\n    postorder(root.left)\r\n    postorder(root.right)\r\n    yield root.value\r\n  end if\r\nend postorder\r\n```\r\n     \r\n## Complexities\r\n\r\n### Time Complexity\r\n\r\n| Access    | Search    | Insertion | Deletion  |\r\n| :-------: | :-------: | :-------: | :-------: |\r\n| O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) |\r\n\r\n### Space Complexity\r\n\r\nO(n)\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Binary_search_tree)\r\n- [Inserting to BST on YouTube](https://www.youtube.com/watch?v=wcIRPqTR3Kc&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8&index=9&t=0s)\r\n- [BST Interactive Visualisations](https://www.cs.usfca.edu/~galles/visualization/BST.html)\r\n",
      "html": "<h1>Binary Search Tree</h1>\n<p>In computer science, <strong>binary search trees</strong> (BST), sometimes called\nordered or sorted binary trees, are a particular type of container:\ndata structures that store “items” (such as numbers, names etc.)\nin memory. They allow fast lookup, addition and removal of\nitems, and can be used to implement either dynamic sets of\nitems, or lookup tables that allow finding an item by its key\n(e.g., finding the phone number of a person by name).</p>\n<p>Binary search trees keep their keys in sorted order, so that lookup\nand other operations can use the principle of binary search:\nwhen looking for a key in a tree (or a place to insert a new key),\nthey traverse the tree from root to leaf, making comparisons to\nthe operations to skip about half of the tree, so that each\nlookup, insertion or deletion takes time proportional to the\nlogarithm of the number of items stored in the tree. This is\nmuch better than the linear time required to find items by key\nin an (unsorted) array, but slower than the corresponding\noperations on hash tables.</p>\n<p>A binary search tree of size 9 and depth 3, with 8 at the root.\nThe leaves are not drawn.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/da/Binary_search_tree.svg\" alt=\"Binary Search Tree\"></p>\n<h2>Pseudocode for Basic Operations</h2>\n<h3>Insertion</h3>\n<pre><code class=\"language-text\">insert(value)\n  Pre: value has passed custom type checks for type T\n  Post: value has been placed in the correct location in the tree\n  if root = ø\n    root ← node(value)\n  else\n    insertNode(root, value)\n  end if\nend insert\n</code></pre>\n<pre><code class=\"language-text\">insertNode(current, value)\n  Pre: current is the node to start from\n  Post: value has been placed in the correct location in the tree\n  if value &lt; current.value\n    if current.left = ø\n      current.left ← node(value)\n    else\n      InsertNode(current.left, value)\n    end if\n  else\n    if current.right = ø\n      current.right ← node(value)\n    else\n      InsertNode(current.right, value)\n    end if\n  end if\nend insertNode\n</code></pre>\n<h3>Searching</h3>\n<pre><code class=\"language-text\">contains(root, value)\n  Pre: root is the root node of the tree, value is what we would like to locate\n  Post: value is either located or not\n  if root = ø\n    return false\n  end if\n  if root.value = value\n    return true\n  else if value &lt; root.value\n    return contains(root.left, value)\n  else\n    return contains(root.right, value)\n  end if\nend contains\n</code></pre>\n<h3>Deletion</h3>\n<pre><code class=\"language-text\">remove(value)\n  Pre: value is the value of the node to remove, root is the node of the BST\n      count is the number of items in the BST\n  Post: node with value is removed if found in which case yields true, otherwise false\n  nodeToRemove ← findNode(value)\n  if nodeToRemove = ø\n    return false\n  end if\n  parent ← findParent(value)\n  if count = 1\n    root ← ø\n  else if nodeToRemove.left = ø and nodeToRemove.right = ø\n    if nodeToRemove.value &lt; parent.value\n      parent.left ←  nodeToRemove.right\n    else\n      parent.right ← nodeToRemove.right\n    end if\n  else if nodeToRemove.left != ø and nodeToRemove.right != ø\n    next ← nodeToRemove.right\n    while next.left != ø\n      next ← next.left\n    end while\n    if next != nodeToRemove.right\n      remove(next.value)\n      nodeToRemove.value ← next.value\n    else\n      nodeToRemove.value ← next.value\n      nodeToRemove.right ← nodeToRemove.right.right\n    end if\n  else\n    if nodeToRemove.left = ø\n      next ← nodeToRemove.right\n    else\n      next ← nodeToRemove.left\n    end if\n    if root = nodeToRemove\n      root = next\n    else if parent.left = nodeToRemove\n      parent.left = next\n    else if parent.right = nodeToRemove\n      parent.right = next\n    end if\n  end if\n  count ← count - 1\n  return true\nend remove\n</code></pre>\n<h3>Find Parent of Node</h3>\n<pre><code class=\"language-text\">findParent(value, root)\n  Pre: value is the value of the node we want to find the parent of\n       root is the root node of the BST and is != ø\n  Post: a reference to the prent node of value if found; otherwise ø\n  if value = root.value\n    return ø\n  end if\n  if value &lt; root.value\n    if root.left = ø\n      return ø\n    else if root.left.value = value\n      return root\n    else\n      return findParent(value, root.left)\n    end if\n  else\n    if root.right = ø\n      return ø\n    else if root.right.value = value\n      return root\n    else\n      return findParent(value, root.right)\n    end if\n  end if\nend findParent\n</code></pre>\n<h3>Find Node</h3>\n<pre><code class=\"language-text\">findNode(root, value)\n  Pre: value is the value of the node we want to find the parent of\n       root is the root node of the BST\n  Post: a reference to the node of value if found; otherwise ø\n  if root = ø\n    return ø\n  end if\n  if root.value = value\n    return root\n  else if value &lt; root.value\n    return findNode(root.left, value)\n  else\n    return findNode(root.right, value)\n  end if\nend findNode\n</code></pre>\n<h3>Find Minimum</h3>\n<pre><code class=\"language-text\">findMin(root)\n  Pre: root is the root node of the BST\n    root = ø\n  Post: the smallest value in the BST is located\n  if root.left = ø\n    return root.value\n  end if\n  findMin(root.left)\nend findMin\n</code></pre>\n<h3>Find Maximum</h3>\n<pre><code class=\"language-text\">findMax(root)\n  Pre: root is the root node of the BST\n    root = ø\n  Post: the largest value in the BST is located\n  if root.right = ø\n    return root.value\n  end if\n  findMax(root.right)\nend findMax\n</code></pre>\n<h3>Traversal</h3>\n<h4>InOrder Traversal</h4>\n<pre><code class=\"language-text\">inorder(root)\n  Pre: root is the root node of the BST\n  Post: the nodes in the BST have been visited in inorder\n  if root = ø\n    inorder(root.left)\n    yield root.value\n    inorder(root.right)\n  end if\nend inorder\n</code></pre>\n<h4>PreOrder Traversal</h4>\n<pre><code class=\"language-text\">preorder(root)\n  Pre: root is the root node of the BST\n  Post: the nodes in the BST have been visited in preorder\n  if root = ø\n    yield root.value\n    preorder(root.left)\n    preorder(root.right)\n  end if\nend preorder\n</code></pre>\n<h4>PostOrder Traversal</h4>\n<pre><code class=\"language-text\">postorder(root)\n  Pre: root is the root node of the BST\n  Post: the nodes in the BST have been visited in postorder\n  if root = ø\n    postorder(root.left)\n    postorder(root.right)\n    yield root.value\n  end if\nend postorder\n</code></pre>\n<h2>Complexities</h2>\n<h3>Time Complexity</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Access</th>\n<th style=\"text-align:center\">Search</th>\n<th style=\"text-align:center\">Insertion</th>\n<th style=\"text-align:center\">Deletion</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">O(log(n))</td>\n<td style=\"text-align:center\">O(log(n))</td>\n<td style=\"text-align:center\">O(log(n))</td>\n<td style=\"text-align:center\">O(log(n))</td>\n</tr>\n</tbody>\n</table>\n<h3>Space Complexity</h3>\n<p>O(n)</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Binary_search_tree\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=wcIRPqTR3Kc&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8&amp;index=9&amp;t=0s\">Inserting to BST on YouTube</a></li>\n<li><a href=\"https://www.cs.usfca.edu/~galles/visualization/BST.html\">BST Interactive Visualisations</a></li>\n</ul>\n",
      "id": 12
    },
    {
      "path": "sets-and-maps/hash-map.md",
      "url": "sets-and-maps/hash-map.html",
      "content": "# Hash Table\r\n\r\nIn computing, a **hash table** (hash map) is a data \r\nstructure which implements an *associative array* \r\nabstract data type, a structure that can *map keys \r\nto values*. A hash table uses a *hash function* to \r\ncompute an index into an array of buckets or slots, \r\nfrom which the desired value can be found\r\n\r\nIdeally, the hash function will assign each key to a \r\nunique bucket, but most hash table designs employ an \r\nimperfect hash function, which might cause hash \r\ncollisions where the hash function generates the same\r\nindex for more than one key. Such collisions must be\r\naccommodated in some way.\r\n\r\n![Hash Table](https://upload.wikimedia.org/wikipedia/commons/7/7d/Hash_table_3_1_1_0_1_0_0_SP.svg)\r\n\r\nHash collision resolved by separate chaining.\r\n\r\n![Hash Collision](https://upload.wikimedia.org/wikipedia/commons/d/d0/Hash_table_5_0_1_1_1_1_1_LL.svg)\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Hash_table)\r\n- [YouTube](https://www.youtube.com/watch?v=shs0KM3wKv8&index=4&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Hash Table</h1>\n<p>In computing, a <strong>hash table</strong> (hash map) is a data\nstructure which implements an <em>associative array</em>\nabstract data type, a structure that can <em>map keys\nto values</em>. A hash table uses a <em>hash function</em> to\ncompute an index into an array of buckets or slots,\nfrom which the desired value can be found</p>\n<p>Ideally, the hash function will assign each key to a\nunique bucket, but most hash table designs employ an\nimperfect hash function, which might cause hash\ncollisions where the hash function generates the same\nindex for more than one key. Such collisions must be\naccommodated in some way.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7d/Hash_table_3_1_1_0_1_0_0_SP.svg\" alt=\"Hash Table\"></p>\n<p>Hash collision resolved by separate chaining.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d0/Hash_table_5_0_1_1_1_1_1_LL.svg\" alt=\"Hash Collision\"></p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Hash_table\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=shs0KM3wKv8&amp;index=4&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">YouTube</a></li>\n</ul>\n",
      "id": 13
    },
    {
      "path": "sets-and-maps/heap.md",
      "url": "sets-and-maps/heap.html",
      "content": "# Heap (data-structure)\r\n\r\nIn computer science, a **heap** is a specialized tree-based \r\ndata structure that satisfies the heap property described\r\nbelow.\r\n\r\nIn a *min heap*, if `P` is a parent node of `C`, then the\r\nkey (the value) of `P` is less than or equal to the\r\nkey of `C`.\r\n\r\n![MinHeap](https://upload.wikimedia.org/wikipedia/commons/6/69/Min-heap.png)\r\n\r\nIn a *max heap*, the key of `P` is greater than or equal\r\nto the key of `C`\r\n\r\n![Heap](https://upload.wikimedia.org/wikipedia/commons/3/38/Max-Heap.svg)\r\n\r\nThe node at the \"top\" of the heap with no parents is \r\ncalled the root node.\r\n\r\n## References\r\n\r\n- [Wikipedia](https://en.wikipedia.org/wiki/Heap_(data_structure))\r\n- [YouTube](https://www.youtube.com/watch?v=t0Cq6tVNRBA&index=5&t=0s&list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8)\r\n",
      "html": "<h1>Heap (data-structure)</h1>\n<p>In computer science, a <strong>heap</strong> is a specialized tree-based\ndata structure that satisfies the heap property described\nbelow.</p>\n<p>In a <em>min heap</em>, if <code>P</code> is a parent node of <code>C</code>, then the\nkey (the value) of <code>P</code> is less than or equal to the\nkey of <code>C</code>.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/6/69/Min-heap.png\" alt=\"MinHeap\"></p>\n<p>In a <em>max heap</em>, the key of <code>P</code> is greater than or equal\nto the key of <code>C</code></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/3/38/Max-Heap.svg\" alt=\"Heap\"></p>\n<p>The node at the “top” of the heap with no parents is\ncalled the root node.</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Heap_(data_structure)\">Wikipedia</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=t0Cq6tVNRBA&amp;index=5&amp;t=0s&amp;list=PLLXdhg_r2hKA7DPDsunoDZ-Z769jWn4R8\">YouTube</a></li>\n</ul>\n",
      "id": 14
    }
  ]
}